{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    return cv2.resize(img , (4*124 , 4*64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "\n",
    "    \n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the range of skin color in HSV\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    # Create a mask using the skin color range\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Dilate the mask to remove small holes in the object\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=4)\n",
    "\n",
    "    # Apply Gaussian blur to the mask to remove noise\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 100)\n",
    "\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=hand_mask)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    # Check if the image is already grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        gray = img\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    # Extract the hand segment from the image\n",
    "    hand = extract_hand_segment(img)\n",
    "\n",
    "    # Resize the hand segment to match the input image dimensions\n",
    "    resized_hand = cv2.resize(hand, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Apply edge detection to the hand segment\n",
    "    edges = cv2.Canny(resized_hand, 50, 150)\n",
    "\n",
    "    # Dilate the edges to fill in gaps\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "\n",
    "    # Apply the dilated edges as a mask to the input image\n",
    "    mask = cv2.cvtColor(dilated_edges, cv2.COLOR_GRAY2BGR)\n",
    "    masked_img = np.zeros_like(img)\n",
    "    masked_img[mask > 0] = img[mask > 0]\n",
    "\n",
    "    resized = resize_image(masked_img)\n",
    "\n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeDetection(img):\n",
    "    return cv2.Canny(img, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img):\n",
    "    return cv2.resize(img , (128*4 , 64*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "X = []\n",
    "y = []\n",
    "D = []\n",
    "L = []\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 6):\n",
    "        filename = 'images/{}_men ({}).JPG'.format(i, j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "\n",
    "        finalImage = preProcessing(img)\n",
    "        keypoints, descriptors = orb.detectAndCompute(finalImage, None)\n",
    "        D.append(descriptors)\n",
    "        L.append(i*np.ones(len(descriptors)))\n",
    "        filename = 'images/{}_woman ({}).JPG'.format(i, j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "\n",
    "        finalImage = preProcessing(img)\n",
    "        keypoints, descriptors = orb.detectAndCompute(finalImage, None)\n",
    "        D.append(descriptors)\n",
    "        L.append(i*np.ones(len(descriptors)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(D)\n",
    "Y = np.hstack(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10000,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=50000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the MLP classifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10000,), max_iter=50000, random_state=42)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21918861757354355\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-cvcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
