{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.resize(gray , (128 , 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "    # Convert the input BGR image to the YCrCb color space\n",
    "    ycrcb_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Split the channels of the YCrCb image into Y, Cr, and Cb channels\n",
    "    y_channel, cr_channel, cb_channel = cv2.split(ycrcb_image)\n",
    "\n",
    "    # Thresholding to create a binary mask for the hand region based on Cr and Cb channels\n",
    "    _, cr_mask = cv2.threshold(cr_channel, 133, 173, cv2.THRESH_BINARY)\n",
    "    _, cb_mask = cv2.threshold(cb_channel, 77, 127, cv2.THRESH_BINARY)\n",
    "    hand_mask = cv2.bitwise_and(cr_mask, cb_mask)\n",
    "\n",
    "    # Dilate the hand mask to fill in any gaps\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated_mask = cv2.dilate(hand_mask, kernel, iterations=7)\n",
    "\n",
    "    # Apply a closing operation to fill any black gaps in the hand\n",
    "    closed_mask = cv2.morphologyEx(dilated_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(closed_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(dilated_mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Apply erosion to reduce the size of the segmented area\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded_mask = cv2.erode(hand_mask, kernel, iterations=12)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=eroded_mask)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation functions\n",
    "def flip(image):\n",
    "    # Flip the image horizontally\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "def rotate(image):\n",
    "    # Rotate the image by 30 degrees\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    \n",
    "    # Segment the hand\n",
    "    img = extract_hand_segment(img)\n",
    "\n",
    "    # Resize the image\n",
    "    img = resize_image(img)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(img):\n",
    "\n",
    "    # Rotate the image\n",
    "    rotated = rotate(img)\n",
    "\n",
    "    # Flip the rotated image\n",
    "    flipped = flip(rotated)\n",
    "\n",
    "    return flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "X = []\n",
    "y = []\n",
    "images = []\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 180):\n",
    "        filename = 'men/{}/{}_men ({}).JPG'.format(i, i , j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "        \n",
    "        # Preprocess the image\n",
    "        finalImg = preProcessing(img)\n",
    "\n",
    "        # Save the final image to array of images\n",
    "        images.append(finalImg)\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "        \n",
    "\n",
    "        # Make new image of the preprocessed image \n",
    "        augmentedImage = augmentation(finalImg)\n",
    "\n",
    "        # Save the new image to array of images\n",
    "        images.append(augmentedImage)\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "\n",
    "\n",
    "        filename = 'Woman/{}/{}_woman ({}).JPG'.format(i, i, j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "\n",
    "        # Preprocess the image\n",
    "        finalImg = preProcessing(img)\n",
    "\n",
    "        # Save the final image to array of images\n",
    "        images.append(finalImg)\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "        \n",
    "\n",
    "        # Make new image of the preprocessed image \n",
    "        augmentedImage = augmentation(finalImg)\n",
    "\n",
    "        # Save the new image to array of images\n",
    "        images.append(augmentedImage)\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hog features from the preprocessed images and save it.\n",
    "hog_features = hog(images[0], orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "X = np.zeros((len(y) , len(hog_features)))\n",
    "for i in range(len(y)):\n",
    "     hog_features = hog(images[i], orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "     X[i] = (np.array(hog_features))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear kernel: 69.0909090909091%\n",
      "Accuracy of poly kernel: 82.51748251748252%\n",
      "Accuracy of rbf kernel: 83.63636363636363%\n",
      "Accuracy of sigmoid kernel: 24.055944055944057%\n"
     ]
    }
   ],
   "source": [
    "# Try different svm kernels to find the best one for this application.\n",
    "kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    # Train the SVM model\n",
    "    model = svm.SVC(kernel=i, C=100, gamma=0.1, degree=6)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f'Accuracy of {i} kernel: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of rbf kernel: 83.63636363636363%\n"
     ]
    }
   ],
   "source": [
    "# Fit the data into the best model.\n",
    "model = svm.SVC(kernel='rbf', C=100, gamma=0.1, degree=6)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Accuracy of rbf kernel: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file.\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
