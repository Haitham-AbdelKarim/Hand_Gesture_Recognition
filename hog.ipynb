{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    # Check if the image is already grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        gray = img\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blurring with a kernel size of 5x5 and sigma of 0\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "\n",
    "    # Apply histogram equalization to enhance the contrast of the image\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentHandRegion(gray):\n",
    "    # Segment the hand region\n",
    "    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    contours, hierarchy = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    hand_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(hand_contour)\n",
    "    hand_roi = gray[y:y+h, x:x+w]\n",
    "    return hand_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.resize(gray , (128 , 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "     # Convert BGR image to YCrCb color space\n",
    "    ycrcb_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Split the channels\n",
    "    y_channel, cr_channel, cb_channel = cv2.split(ycrcb_image)\n",
    "\n",
    "    # Thresholding to create a binary mask for hand region\n",
    "    _, cr_mask = cv2.threshold(cr_channel, 133, 173, cv2.THRESH_BINARY)\n",
    "    _, cb_mask = cv2.threshold(cb_channel, 77, 127, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Combine the masks\n",
    "    mask = cv2.bitwise_and(cr_mask, cb_mask)\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Dilate the hand mask to fill in any gaps\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    dilated_mask = cv2.dilate(hand_mask, kernel, iterations=1)\n",
    "\n",
    "    # Apply erosion to reduce the size of the segmented area\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=1)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=eroded_mask)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation functions\n",
    "def flip(image):\n",
    "    # Flip the image horizontally\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "def rotate(image):\n",
    "    # Rotate the image by 30 degrees\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "# Prepare the training data\n",
    "X = []\n",
    "y = []\n",
    "images = []\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 180):\n",
    "        filename = 'men/{}/{}_men ({}).JPG'.format(i, i , j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "        hand_roi = extract_hand_segment(img)\n",
    "        finalImg = resizeImage(hand_roi)\n",
    "        images.append(finalImg)\n",
    "        y.append(i)\n",
    "        count += 1\n",
    "\n",
    "\n",
    "        filename = 'Woman/{}/{}_woman ({}).JPG'.format(i, i, j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "\n",
    "        hand_roi = extract_hand_segment(img)\n",
    "        finalImg = resizeImage(hand_roi)\n",
    "        images.append(finalImg)\n",
    "        y.append(i)\n",
    "        count += 1\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796\n",
      "1796\n"
     ]
    }
   ],
   "source": [
    "hog_features = hog(images[0], orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "X = np.zeros((len(y) , len(hog_features)))\n",
    "for i in range(len(y)):\n",
    "     hog_features = hog(images[i], orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "     X[i] = (np.array(hog_features))\n",
    "print(len(X))     \n",
    "print(len(y))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.94444444444444%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
