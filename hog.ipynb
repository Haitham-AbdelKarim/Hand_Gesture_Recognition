{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img , width , height):\n",
    "    return cv2.resize(img , (width , height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "    # Convert the input BGR image to the YCrCb color space\n",
    "    ycrcb_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Split the channels of the YCrCb image into Y, Cr, and Cb channels\n",
    "    y_channel, cr_channel, cb_channel = cv2.split(ycrcb_image)\n",
    "\n",
    "    # Thresholding to create a binary mask for the hand region based on Cr and Cb channels\n",
    "    _, cr_mask = cv2.threshold(cr_channel, 133, 173, cv2.THRESH_BINARY)\n",
    "    _, cb_mask = cv2.threshold(cb_channel, 77, 127, cv2.THRESH_BINARY)\n",
    "    hand_mask = cv2.bitwise_and(cr_mask, cb_mask)\n",
    "\n",
    "    # Dilate the hand mask to fill in any gaps\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    dilated_mask = cv2.dilate(hand_mask, kernel, iterations=1)\n",
    "\n",
    "    # Apply a closing operation to fill any black gaps in the hand\n",
    "    closed_mask = cv2.morphologyEx(dilated_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(closed_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(dilated_mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Apply erosion to reduce the size of the segmented area\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    eroded_mask = cv2.erode(hand_mask, kernel, iterations=1)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=eroded_mask)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_closing(image, kernel_size=(150, 150)):\n",
    "    # Convert the image to YCrCb color space\n",
    "    ycrcb_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Split the channels\n",
    "    _, cr_channel, cb_channel = cv2.split(ycrcb_image)\n",
    "\n",
    "    # Thresholding to create a binary mask for hand region\n",
    "    _, cr_mask = cv2.threshold(cr_channel, 133, 173, cv2.THRESH_BINARY)\n",
    "    _, cb_mask = cv2.threshold(cb_channel, 77, 127, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Combine the masks\n",
    "    mask = cv2.bitwise_and(cr_mask, cb_mask)\n",
    "\n",
    "    # Apply morphological closing to fill gaps in the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n",
    "    mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Apply the mask to the original image to extract the hand region\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=mask_closed)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation functions\n",
    "def flip(image):\n",
    "    # Flip the image horizontally\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "def rotate(image):\n",
    "    # Rotate the image by 30 degrees\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 180, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(image):\n",
    "    image = resize_image(image , 4*128 , 4*64)\n",
    "    image = extract_hand_segment(image)\n",
    "    # image = apply_closing(image)    \n",
    "    image = resize_image(image , 128 , 64)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(img):\n",
    "    images = []\n",
    "\n",
    "    # Rotate the image\n",
    "    rotated = rotate(img)\n",
    "    images.append(rotated)\n",
    "\n",
    "    # Flip the rotated image\n",
    "    flipped = flip(img)\n",
    "    images.append(flipped)\n",
    "\n",
    "    rotatedFlipped = flip(rotated)\n",
    "    images.append(rotatedFlipped)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "X = []\n",
    "y = []\n",
    "images = []\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 180):\n",
    "        filename = 'men/{}/{}_men ({}).JPG'.format(i, i , j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "        \n",
    "        # Preprocess the image\n",
    "        finalImg = preProcessing(img)\n",
    "\n",
    "        # Save the final image to array of images\n",
    "        images.append(finalImg)\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "        \n",
    "\n",
    "        # Make new image of the preprocessed image \n",
    "        augmentedImages = augmentation(finalImg)\n",
    "\n",
    "        # Save the new image to array of images\n",
    "        images.append(augmentedImages[0])\n",
    "        images.append(augmentedImages[1])\n",
    "        images.append(augmentedImages[2])\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "        y.append(i)\n",
    "        y.append(i)\n",
    "\n",
    "\n",
    "        filename = 'Woman/{}/{}_woman ({}).JPG'.format(i, i, j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "\n",
    "        # Preprocess the image\n",
    "        finalImg = preProcessing(img)\n",
    "\n",
    "        # Save the final image to array of images\n",
    "        images.append(finalImg)\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "        \n",
    "\n",
    "        # Make new image of the preprocessed image \n",
    "        augmentedImages = augmentation(finalImg)\n",
    "\n",
    "        # Save the new image to array of images\n",
    "        images.append(augmentedImages[0])\n",
    "        images.append(augmentedImages[1])\n",
    "        images.append(augmentedImages[2])\n",
    "\n",
    "        # Save the label of the image\n",
    "        y.append(i)\n",
    "        y.append(i)\n",
    "        y.append(i)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hog features from the preprocessed images and save it.\n",
    "hog_features = hog(images[0], orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "X = np.zeros((len(y) , len(hog_features)))\n",
    "for i in range(len(y)):\n",
    "     hog_features = hog(images[i], orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "     X[i] = (np.array(hog_features))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear kernel: 70.46885934219735%\n",
      "Accuracy of poly kernel: 84.53463960811757%\n",
      "Accuracy of rbf kernel: 84.1147655703289%\n",
      "Accuracy of sigmoid kernel: 26.172148355493352%\n"
     ]
    }
   ],
   "source": [
    "# Try different svm kernels to find the best one for this application.\n",
    "kernel= ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in kernel:\n",
    "    # Train the SVM model\n",
    "    model = svm.SVC(kernel=i, C=100, gamma=0.1, degree=6)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f'Accuracy of {i} kernel: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of poly kernel: 84.53463960811757%\n"
     ]
    }
   ],
   "source": [
    "# Fit the data into the best model.\n",
    "model = svm.SVC(kernel='poly', C=100, gamma=0.1, degree=6)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Accuracy of poly kernel: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file.\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
