{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    # Check if the image is already grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        gray = img\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blurring with a kernel size of 5x5 and sigma of 0\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "\n",
    "    # Apply histogram equalization to enhance the contrast of the image\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentHandRegion(gray):\n",
    "    # Segment the hand region\n",
    "    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    contours, hierarchy = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    hand_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(hand_contour)\n",
    "    hand_roi = gray[y:y+h, x:x+w]\n",
    "    return hand_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img):\n",
    "    return cv2.resize(img , (128*4 , 64*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the average brightness of the image\n",
    "    brightness = np.mean(hsv[:, :, 2])\n",
    "\n",
    "    # Define the range of skin color based on image brightness\n",
    "    lower_skin = np.array([0, 45, min(90, brightness - 40)], dtype=np.uint8)\n",
    "    upper_skin = np.array([30, 255, min(255, brightness + 40)], dtype=np.uint8)\n",
    "\n",
    "    # Create a mask using the skin color range\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Dilate the mask to remove small holes in the object\n",
    "    kernel = np.ones((25, 25), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=25)\n",
    "\n",
    "    # Apply Gaussian blur to the mask to remove noise\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 100)\n",
    "\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Dilate the hand mask to fill in any gaps\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    dilated_mask = cv2.dilate(hand_mask, kernel, iterations=5)\n",
    "\n",
    "    # Apply erosion to reduce the size of the segmented area\n",
    "    kernel = np.ones((25, 25), np.uint8)\n",
    "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=20)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=eroded_mask)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation functions\n",
    "def flip(image):\n",
    "    # Flip the image horizontally\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "def rotate(image):\n",
    "    # Rotate the image by 30 degrees\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 180):\n",
    "        filename = 'men/{}/{}_men ({}).JPG'.format(i, i , j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "        hand_roi = extract_hand_segment(img)\n",
    "        finalImg = resizeImage(hand_roi)\n",
    "        hog_features = hog(finalImg, orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "        X.append(np.array(hog_features))\n",
    "        y.append(i)\n",
    "\n",
    "        # rotated = rotate(finalImg)\n",
    "        # hog_features = hog(rotated, orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "        # X.append(np.array(hog_features))\n",
    "        # y.append(i)\n",
    "\n",
    "        # flipped = flip(finalImg)\n",
    "        # hog_features = hog(flipped, orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "        # X.append(np.array(hog_features))\n",
    "        # y.append(i)\n",
    "\n",
    "        filename = 'Woman/{}/{}_woman ({}).JPG'.format(i, i, j)\n",
    "        img = cv2.imread(filename)\n",
    "        if  img is None:\n",
    "            continue    \n",
    "        \n",
    "\n",
    "        hand_roi = extract_hand_segment(img)\n",
    "        finalImg = resizeImage(hand_roi)\n",
    "        hog_features = hog(finalImg, orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "        X.append(np.array(hog_features))\n",
    "        y.append(i)\n",
    "\n",
    "        \n",
    "        # rotated = rotate(finalImg)\n",
    "        # hog_features = hog(rotated, orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "        # X.append(np.array(hog_features))\n",
    "        # y.append(i)\n",
    "\n",
    "        # flipped = flip(finalImg)\n",
    "        # hog_features = hog(flipped, orientations=12, pixels_per_cell=(12, 12), cells_per_block=(3, 3), block_norm='L2-Hys')\n",
    "        # X.append(np.array(hog_features))\n",
    "        # y.append(i)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
