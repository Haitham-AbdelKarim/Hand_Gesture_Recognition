{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation functions\n",
    "def flip(image):\n",
    "    # Flip the image horizontally\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "def rotate(image):\n",
    "    # Rotate the image by 30 degrees\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(img):\n",
    "    return cv2.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    return cv2.resize(img , (4*124 , 4*64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_remove(img):\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # rgb_planes = cv2.split(img)\n",
    "    # result_norm_planes = []\n",
    "    # for plane in rgb_planes:\n",
    "    #     dilated_img = cv2.dilate(plane, np.ones((7,7), np.uint8))\n",
    "    #     bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "    #     diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
    "    #     norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    #     result_norm_planes.append(norm_img)\n",
    "    # shadowremov = cv2.merge(result_norm_planes)\n",
    "    # # shadowremov [ shadowremov > 250] = 0\n",
    "    # shadowremov = 255 - shadowremov\n",
    "    # return shadowremov\n",
    "\n",
    "    # # first part\n",
    "    # black_indices = np.all(img < 50, axis=2)\n",
    "    # img[black_indices] = [0, 0, 0]\n",
    "\n",
    "    # # second part\n",
    "    # red = img[:, :, 2]\n",
    "    # green = img[:, :, 1]\n",
    "    # blue = img[:, :, 0]\n",
    "\n",
    "    # maxColor = np.argmax(img, axis=2)\n",
    "    # # 0 -> blue\n",
    "    # # 1 -> green\n",
    "    # # 2 -> red\n",
    "\n",
    "    # img[(maxColor == 0) & (blue - green > 50)] = [255, 0, 0]\n",
    "    # img[(maxColor == 1) & (green - blue > 50)] = [0, 255, 0]\n",
    "    # img[(maxColor != 0) & (maxColor != 1)] = [0, 0, 0]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the average brightness of the image\n",
    "    brightness = np.mean(hsv[:, :, 2])\n",
    "\n",
    "    # Define the range of skin color based on image brightness\n",
    "    lower_skin = np.array([0, 45, min(90, brightness - 40)], dtype=np.uint8)\n",
    "    upper_skin = np.array([30, 255, min(255, brightness + 40)], dtype=np.uint8)\n",
    "\n",
    "    # Create a mask using the skin color range\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Dilate the mask to remove small holes in the object\n",
    "    kernel = np.ones((25, 25), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=25)\n",
    "\n",
    "    # Apply Gaussian blur to the mask to remove noise\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 100)\n",
    "\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Dilate the hand mask to fill in any gaps\n",
    "    kernel = np.ones((20, 20), np.uint8)\n",
    "    dilated_mask = cv2.dilate(hand_mask, kernel, iterations=10)\n",
    "\n",
    "    # Apply erosion to reduce the size of the segmented area\n",
    "    kernel = np.ones((25, 25), np.uint8)\n",
    "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=35)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=eroded_mask)\n",
    "\n",
    "    # Remove shadows from the hand segment\n",
    "    hand_segment_no_shadow = shadow_remove(hand_segment)\n",
    "\n",
    "    # Create a mask of the hand region with no shadows and no background\n",
    "    hand_mask_no_shadow = cv2.bitwise_and(hand_mask, cv2.bitwise_not(hand_segment_no_shadow))\n",
    "\n",
    "    # Apply the hand mask with no shadows and no background to the original image\n",
    "    hand_segment_final = cv2.bitwise_and(image, image, mask=hand_mask_no_shadow)\n",
    "\n",
    "    # Return the segmented hand image with no shadows and no background\n",
    "    return hand_segment_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified images are saved in: d:\\MOHAMED ENGINEERING\\cmp\\third year\\second\\Neural networks\\Project\\test\\result\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"result\"\n",
    "cwd = os.getcwd()\n",
    "full_path = os.path.join(cwd, folder_path)\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 6):\n",
    "        # Read input image for men\n",
    "        men_filename = 'images/{}_men ({}).JPG'.format(i, j)\n",
    "        men_image = cv2.imread(men_filename)\n",
    "        if men_image is not None:\n",
    "            #men_final = extract_hand_segment(men_image)\n",
    "            men_final = shadow_remove(men_image)\n",
    "            men_modified_filename = f\"modified_{i}_men_{j}.jpg\"\n",
    "            men_modified_path = os.path.join(full_path, men_modified_filename)\n",
    "            cv2.imwrite(men_modified_path, men_final)\n",
    "\n",
    "        # Read input image for women\n",
    "        women_filename = 'images/{}_woman ({}).JPG'.format(i, j)\n",
    "        women_image = cv2.imread(women_filename)\n",
    "        if women_image is not None:\n",
    "            #women_final = extract_hand_segment(women_image)\n",
    "            women_final = shadow_remove(women_image)\n",
    "            women_modified_filename = f\"modified_{i}_woman_{j}.jpg\"\n",
    "            women_modified_path = os.path.join(full_path, women_modified_filename)\n",
    "            cv2.imwrite(women_modified_path, women_final)\n",
    "\n",
    "print(f\"Modified images are saved in: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-cvcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
