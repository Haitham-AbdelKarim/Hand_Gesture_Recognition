{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformation functions\n",
    "def flip(image):\n",
    "    # Flip the image horizontally\n",
    "    return cv2.flip(image, 1)\n",
    "\n",
    "def rotate(image):\n",
    "    # Rotate the image by 30 degrees\n",
    "    rows, cols = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), 30, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(img):\n",
    "    return cv2.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    return cv2.resize(img , (4*124 , 4*64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand_segment(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the average brightness of the image\n",
    "    brightness = np.mean(hsv[:, :, 2])\n",
    "\n",
    "    # Define the range of skin color based on image brightness\n",
    "    lower_skin = np.array([0, 35, min(90, brightness - 40)], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, min(255, brightness + 40)], dtype=np.uint8)\n",
    "\n",
    "    # Create a mask using the skin color range\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Dilate the mask to remove small holes in the object\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=20)\n",
    "\n",
    "    # Apply Gaussian blur to the mask to remove noise\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 100)\n",
    "\n",
    "    # Find the contours of the object in the mask\n",
    "    _, contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Create a mask of the hand contour\n",
    "    hand_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, cv2.FILLED)\n",
    "\n",
    "    # Dilate the hand mask to fill in any gaps\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    dilated_mask = cv2.dilate(hand_mask, kernel, iterations=10)\n",
    "\n",
    "    # Apply erosion to reduce the size of the segmented area\n",
    "    kernel = np.ones((12, 12), np.uint8)\n",
    "    eroded_mask = cv2.erode(dilated_mask, kernel, iterations=10)\n",
    "\n",
    "    # Apply the hand mask to the original image to extract the hand\n",
    "    hand_segment = cv2.bitwise_and(image, image, mask=eroded_mask)\n",
    "\n",
    "    # Return the segmented hand image\n",
    "    return hand_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_closing(img):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the grayscale image to create a binary image\n",
    "    _, bin_img = cv2.threshold(gray, 0, 200, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    # Create a structuring element for the closing operation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "    # Apply closing to the binary image\n",
    "    closing = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Convert the binary image back to BGR format\n",
    "    result = cv2.cvtColor(closing, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img):\n",
    "    # Check if the image is already grayscale\n",
    "    if len(img.shape) == 2:\n",
    "        gray = img\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    # Extract the hand segment from the image\n",
    "    hand = extract_hand_segment(img)\n",
    "\n",
    "    \n",
    "\n",
    "    return hand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_shadows(image):\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply adaptive thresholding to create a binary mask\n",
    "    mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 8)\n",
    "\n",
    "    # apply a median blur to smooth the edges of the mask\n",
    "    mask = cv2.medianBlur(mask, 15)\n",
    "\n",
    "    # dilate the mask to fill in any gaps\n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations = 10)\n",
    "\n",
    "    # apply the mask to the original image to remove shadows\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hand(image):\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply thresholding to create a binary mask\n",
    "    _, mask = cv2.threshold(gray, 170, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # apply morphological operations to remove noise\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # find the largest contour (should be the hand)\n",
    "    contours,_ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # create a mask for the hand contour\n",
    "    hand_mask = np.zeros(image.shape[:2], np.uint8)\n",
    "    cv2.drawContours(hand_mask, [largest_contour], 0, 255, -1)\n",
    "\n",
    "    # apply the hand mask to the original image to extract the hand\n",
    "    hand = cv2.bitwise_and(image, image, mask=hand_mask)\n",
    "\n",
    "    return hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(img):\n",
    "\n",
    "    # Convert the image to the LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB channels\n",
    "    L, A, B = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(L)\n",
    "\n",
    "    # Merge the CLAHE-enhanced L channel with the A and B channels\n",
    "    merged = cv2.merge([cl, A, B])\n",
    "\n",
    "    # Convert the merged image back to the BGR color space\n",
    "    bgr = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Convert the BGR image to grayscale\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to the grayscale image\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Find the contours of the white region\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "    # Get the largest contour (which should be the hand)\n",
    "    contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
    "    largest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
    "\n",
    "    # Draw the hand contour on a blank image\n",
    "    hand_contour = cv2.drawContours(np.zeros_like(gray), [largest_contour], 0, (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Apply Canny edge detection to the hand contour\n",
    "    hand_edges = cv2.Canny(hand_contour, 100, 200)\n",
    "\n",
    "    # Return the hand edges\n",
    "    return hand_edges\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified images are saved in: d:\\MOHAMED ENGINEERING\\cmp\\third year\\second\\Neural networks\\Project\\test\\result\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"result\"\n",
    "cwd = os.getcwd()\n",
    "full_path = os.path.join(cwd, folder_path)\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(1, 6):\n",
    "        # Read input image for men\n",
    "        men_filename = 'images/{}_men ({}).JPG'.format(i, j)\n",
    "        men_image = cv2.imread(men_filename)\n",
    "        if men_image is not None:\n",
    "            men_final = preProcessing(men_image)\n",
    "            men_modified_filename = f\"modified_{i}_men_{j}.jpg\"\n",
    "            men_modified_path = os.path.join(full_path, men_modified_filename)\n",
    "            cv2.imwrite(men_modified_path, cv2.cvtColor(men_final, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        # Read input image for women\n",
    "        women_filename = 'images/{}_woman ({}).JPG'.format(i, j)\n",
    "        women_image = cv2.imread(women_filename)\n",
    "        if women_image is not None:\n",
    "            women_final = preProcessing(women_image)\n",
    "            women_modified_filename = f\"modified_{i}_woman_{j}.jpg\"\n",
    "            women_modified_path = os.path.join(full_path, women_modified_filename)\n",
    "            cv2.imwrite(women_modified_path, cv2.cvtColor(women_final, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "print(f\"Modified images are saved in: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-cvcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
